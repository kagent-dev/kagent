name: GenerateResourceTool Tests
on:
  push:
    branches: [ main ]
    paths:
      - 'kagent/tools/**'
  pull_request:
    branches: [ main ]
    paths:
      - 'kagent/tools/**'
  workflow_dispatch:
jobs:
  similarity-tests:
    runs-on: ubuntu-latest
    
    steps:
    - uses: actions/checkout@v4
    
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: 3.11
    
    - name: Install uv
      uses: astral-sh/setup-uv@v5

    - name: Sync dependencies
      working-directory: ./python
      run: |
        export GIT_LFS_SKIP_SMUDGE=1
        uv sync --all-extras

    - name: Run  tests
      env:
        OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}
      run: |
        NO_FAIL=1 uv run pytest -v | tee pytest_output.log

    - name: Upload pytest output
      uses: actions/upload-artifact@v4
      with:
        name: pytest-output
        path: pytest_output.log
        if-no-files-found: warn

    - name: Upload test reports
      uses: actions/upload-artifact@v4
      with:
        name: test-reports
        path: test_results/
        if-no-files-found: warn
    
    - name: Process test results
      if: always()
      run: |
        # Find the latest JSON report
        LATEST_REPORT=$(ls -t test_results/*.json | head -1)
        
        if [ -f "$LATEST_REPORT" ]; then
          # Extract details from the JSON report
          TOTAL_TESTS=$(jq '.total_tests' $LATEST_REPORT)
          AVG_SIMILARITY=$(jq '.average_similarity' $LATEST_REPORT)
          AVG_SIMILARITY_PCT=$(printf "%.1f%%" $(echo "$AVG_SIMILARITY * 100" | bc -l))
          
          # Count tests by result range
          HIGH_COUNT=$(jq '[.results[] | select(.similarity_score >= 0.9)] | length' $LATEST_REPORT)
          MED_COUNT=$(jq '[.results[] | select(.similarity_score >= 0.7 and .similarity_score < 0.9)] | length' $LATEST_REPORT)
          LOW_COUNT=$(jq '[.results[] | select(.similarity_score < 0.7)] | length' $LATEST_REPORT)
          
          # Output summary as GitHub step summary
          echo "## GenerateResourceTool Test Results" >> $GITHUB_STEP_SUMMARY
          echo "- **Average Similarity:** $AVG_SIMILARITY_PCT" >> $GITHUB_STEP_SUMMARY
          echo "- **Total Tests:** $TOTAL_TESTS" >> $GITHUB_STEP_SUMMARY
          echo "- **High (90-100%):** $HIGH_COUNT" >> $GITHUB_STEP_SUMMARY
          echo "- **Medium (70-89%):** $MED_COUNT" >> $GITHUB_STEP_SUMMARY
          echo "- **Low (0-69%):** $LOW_COUNT" >> $GITHUB_STEP_SUMMARY
          
          # Create GitHub Actions annotations
          if [ $LOW_COUNT -gt 0 ]; then
            echo "::warning::Some tests have low similarity scores"
          fi
          echo "::notice::Test Summary - Average similarity: $AVG_SIMILARITY_PCT, High: $HIGH_COUNT, Medium: $MED_COUNT, Low: $LOW_COUNT"
          
          # Output the pytest log
          echo "### Full Test Output" >> $GITHUB_STEP_SUMMARY
          echo "\`\`\`" >> $GITHUB_STEP_SUMMARY
          cat pytest_output.log >> $GITHUB_STEP_SUMMARY
          echo "\`\`\`" >> $GITHUB_STEP_SUMMARY
        else
          echo "::warning::No test report found"
        fi
